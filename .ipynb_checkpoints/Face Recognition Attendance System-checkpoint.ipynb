{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(70,70)):\n",
    "    image_dir=Path(container_path)\n",
    "    folders=[]\n",
    "    for directory in image_dir.iterdir():\n",
    "            if directory.is_dir():\n",
    "                folders.append(directory);\n",
    "    #print(folders)\n",
    "    categories=[]\n",
    "    for i in  folders:\n",
    "        categories.append(i.name)\n",
    "    #print(categories);\n",
    "    \n",
    "    '''A image classification dataset'''\n",
    "    actual_x = []\n",
    "    actual_y = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        #print(i,direc);\n",
    "        for file in direc.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(cfile);\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            actual_x.append(img_resized.flatten()) \n",
    "            #print(flat_data[0])\n",
    "            actual_y.append(i)\n",
    "    actual_x = np.array(actual_x)\n",
    "    actual_y= np.array(actual_y)\n",
    "    return Bunch(data=actual_x, target=actual_y,target_names=categories)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"traning_image/\")\n",
    "\n",
    "#print(image_dataset.data,image_dataset.target,image_dataset.target_names)\n",
    "#test=load_image_files('fdklfd.cg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393, 4900)\n",
      "(349, 4900)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset.data, image_dataset.target, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G.K\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\G.K\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  9 24  1 22 22 32 28  4 19 13 28 21 28  9 22 17  7  7 24  6 30 21  3\n",
      " 30 21 26 17 19 23 21 31 21  4 21 30 29 28 26 30 14 19  7  3  2 14 24  0\n",
      " 29 18 17 27 23  2 13 12  1  4  6  8 16 16 32  1 20 13 11 20  2 20 19 33\n",
      " 34 33 21  9 25 25  6 31 15 29 17 10  8  5  7 19 15  2 31 34 11  7 19  0\n",
      "  1  3  2 23 18 26  8 26 31 13 18 29 29 11 12 30  4 10 29 18 34 17 12 10\n",
      "  5 17 30  7 16 25 24 31 28 14  5 24 10 31 13 17 33 17 31 34 32 18 32  1\n",
      "  7 32 32  4 16 18 11 15 23 19  9  0 14  5 32 18 15 30 29 16 28 23 23 21\n",
      "  0 12 32  9 22  3  7 18 19 31 13 33 31 24  8 33  6 10 13 17 21  2 11 29\n",
      " 13 12  6  3 23 33 14 29 17 24  8 28 11 13 21 32 26 28  2 10 24 33 10 28\n",
      "  6 20 18  4  1  2 25 26 19 33 16  4  1 22 14 25 15 19 12  5 33 27 29 10\n",
      " 30 18  5 19  3 23 24 22 24 18 23 16 19 33  6  5 23 15  0 31 12 13 30 16\n",
      "  5 14  4 32  6 24 30 24 21 27 11 18 18  1 33 12 10 23 27 14 13 10 32  1\n",
      " 25  8 29 29 23 29 14 28 28 12 19  3  9 22 27 17 14 30 13 19  3  0 22 14\n",
      "  1 33 15 26 10 14 12 27 27 34  2 31 33 16 33 18 21  2 33 33  5 15 32  7\n",
      " 22 30 23  1 34  2  8 21  7 23 10 10 12] 349\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(y_pred,len(y_pred))\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  9 24  1 22 22 32 28  4 19 13 28 21 28  9 22 17  7  7 24  6 30 20  3\n",
      " 30 21 26 17 19 23 21 31 34  4 34 30 29 28 26 30 14 19  7 32 32 14 24 28\n",
      " 29 18 17 27 23  2 13 12  1  4 21  8 16 20 32  1 20 13 11 20  2 20 19 33\n",
      " 34 24 21  9 25 25  6 31 20 29 17 10  8  5  7 19 20  2 31 34 11  7 19  0\n",
      " 30  3 32 23 18 26  8 26 28 13 18 29 29 11 12 20  4 10 29 18 20 17 12 10\n",
      " 20 17 30  7 16 25 24 31 28 14 20 24 10 31 13  8 33 17 31 34 32 18 31 30\n",
      "  7 32 32  4 18 18 11 15 23 19 34  0 14  5 32 18 15  8 29  2 28 23 23 21\n",
      "  0 12 32  9 22  3  7 18 19 31 13 33 31 24  8 33  8 10 13 17 15 32 11 29\n",
      " 13 12  6  3 23 33 14 29 17 24  8 28 11 13 21 32 26 28 32 10 24 33 10 19\n",
      " 21 20 18  4  1 32 25 26 19 33 16  4  1 22 14 25 15 19 12  5 33 27 29 10\n",
      " 20 18  5 19  3 23 24 22 24 18 23  2  7 33  6  5 23 15 31 31 12 13 30 20\n",
      "  5 14  4 32  6 24 30 24 21 27 11 18 18  1 33 12 10 23 27 14 13 10 21  4\n",
      " 11  8 19 29 23 29 14 28 19 12 19 31  9 22 27 17 14 30 13 19 18  0 22 14\n",
      "  1 33 15 26 10 14 12 27 27 34 32 31 33 16 33 18 21  2 33 33  5 15 32  7\n",
      " 28 30 23 30 34  2  8 20  7 23 10 10 12]\n",
      "86 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=21)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face0.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face1.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face2.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face3.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face4.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face5.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face6.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face7.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face8.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face9.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face10.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face11.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face12.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face13.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face14.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face15.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face16.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face17.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face18.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face19.jpg written!\n",
      "C:\\Users\\G.K\\Face Recognition Attendance System\\test_image\\face20.jpg written!\n"
     ]
    }
   ],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')#xml file for face detection\n",
    "video_capture = cv2.VideoCapture(0)#open a vedio\n",
    "img_counter = 0 #count level \n",
    "run=0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()#read a image from vedio\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#convert to gray scale\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.3, 5)#face size\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)#show face position in a frame\n",
    "        roi_gray = gray[y:y+h, x:x+w]#gray scale crop\n",
    "        roi_color = frame[y:y+h, x:x+w]#color image scale crop\n",
    "    k=cv2.waitKey(100)\n",
    "    cv2.imshow('FaceDetection', frame)\n",
    "    \n",
    "    if img_counter ==21: #ESC Pressed\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        run=1;\n",
    "    if(run==1):\n",
    "        img_name = 'C:\\\\Users\\\\G.K\\\\Face Recognition Attendance System\\\\test_image\\\\face{}.jpg'.format(img_counter)\n",
    "        cv2.imwrite(img_name, roi_gray)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "    \n",
    "        \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=Path(\"test_image/\")\n",
    "dimension=(70,70)\n",
    "test_x=[]\n",
    "for file in image_dir.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(cfile);\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            test_x.append(img_resized.flatten())\n",
    "#print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_x)\n",
    "print(y_pred)\n",
    "#test_y=[4,4,4,4,4,4,4,4,4,4]\n",
    "#print(metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.array(y_pred)\n",
    "counts = np.bincount(y_pred)\n",
    "v=np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_id=image_dataset.target_names[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gulam Kibria Chowdhury', '170103020033']\n"
     ]
    }
   ],
   "source": [
    "student=[]\n",
    "for j in name_id.split('_'):\n",
    "            student.append(j)\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gulam Kibria Chowdhury 170103020033 2020-07-07 18:14:28\n"
     ]
    }
   ],
   "source": [
    "col_names =  ['Id','Name','Date','Time']\n",
    "attendance = pd.DataFrame(columns = col_names)\n",
    "ts = time.time()      \n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "aa=student[0]\n",
    "Id=student[1]\n",
    "print(aa,Id,date,timeStamp)\n",
    "attendance.loc[len(attendance)] = [Id,aa,date,timeStamp] \n",
    "attendance=attendance.drop_duplicates(subset=['Id'],keep='first')\n",
    "ts = time.time()      \n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "Hour,Minute,Second=timeStamp.split(\":\")\n",
    "fileName=\"Attendance\\Attendance_\"+date+\"_\"+Hour+\"-\"+Minute+\"-\"+Second+\".csv\"\n",
    "attendance.to_csv(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
